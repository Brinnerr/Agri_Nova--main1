{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåæ Shamba Score: Climate-Adaptive Credit Scoring System\n",
    "\n",
    "## Overview\n",
    "This notebook develops an AI-driven credit scoring system that:\n",
    "- Uses satellite crop imagery for yield assessment\n",
    "- Incorporates local climate forecasts\n",
    "- Analyzes mobile money transaction patterns\n",
    "- Evaluates community reputation scores\n",
    "- Tracks farm input purchase history\n",
    "- Separates climate risks from farmer performance\n",
    "- Provides transparent explanations and recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, classification_report\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"üìä Shamba Score AI System Initialized\")\n",
    "print(\"üåç Climate-Adaptive Credit Scoring for Kenyan Farmers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Sources & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class ShambaScoreDataGenerator:\n",
    "    \"\"\"Generate synthetic data for Shamba Score model development\"\"\"\n",
    "    \n",
    "    def __init__(self, n_farmers=1000):\n",
    "        self.n_farmers = n_farmers\n",
    "        \n",
    "    def generate_satellite_data(self):\n",
    "        \"\"\"Generate satellite crop imagery features\"\"\"\n",
    "        return {\n",
    "            'ndvi_current': np.random.normal(0.7, 0.15, self.n_farmers),\n",
    "            'ndvi_historical_avg': np.random.normal(0.65, 0.12, self.n_farmers),\n",
    "            'crop_health_score': np.random.beta(2, 1, self.n_farmers) * 100,\n",
    "            'field_size_hectares': np.random.exponential(2, self.n_farmers),\n",
    "            'vegetation_consistency': np.random.uniform(0.3, 0.95, self.n_farmers),\n",
    "            'soil_moisture_index': np.random.normal(0.5, 0.2, self.n_farmers)\n",
    "        }\n",
    "    \n",
    "    def generate_climate_data(self):\n",
    "        \"\"\"Generate climate forecast features\"\"\"\n",
    "        return {\n",
    "            'rainfall_forecast_mm': np.random.gamma(2, 50, self.n_farmers),\n",
    "            'temperature_avg_c': np.random.normal(24, 3, self.n_farmers),\n",
    "            'drought_risk_score': np.random.beta(1, 3, self.n_farmers) * 100,\n",
    "            'flood_risk_score': np.random.beta(1, 4, self.n_farmers) * 100,\n",
    "            'climate_variability_index': np.random.uniform(0.1, 0.8, self.n_farmers),\n",
    "            'seasonal_pattern_match': np.random.uniform(0.4, 0.95, self.n_farmers)\n",
    "        }\n",
    "    \n",
    "    def generate_mpesa_data(self):\n",
    "        \"\"\"Generate mobile money transaction features\"\"\"\n",
    "        return {\n",
    "            'monthly_income_avg': np.random.lognormal(9, 0.8, self.n_farmers),\n",
    "            'transaction_frequency': np.random.poisson(25, self.n_farmers),\n",
    "            'savings_rate': np.random.beta(2, 5, self.n_farmers),\n",
    "            'payment_consistency': np.random.uniform(0.5, 0.98, self.n_farmers),\n",
    "            'agricultural_payments_ratio': np.random.beta(3, 2, self.n_farmers),\n",
    "            'seasonal_income_stability': np.random.uniform(0.3, 0.9, self.n_farmers)\n",
    "        }\n",
    "    \n",
    "    def generate_community_data(self):\n",
    "        \"\"\"Generate community reputation features\"\"\"\n",
    "        return {\n",
    "            'community_trust_score': np.random.beta(3, 1, self.n_farmers) * 100,\n",
    "            'cooperative_participation': np.random.binomial(1, 0.6, self.n_farmers),\n",
    "            'peer_recommendations': np.random.poisson(3, self.n_farmers),\n",
    "            'local_leadership_role': np.random.binomial(1, 0.15, self.n_farmers),\n",
    "            'dispute_history': np.random.poisson(0.5, self.n_farmers),\n",
    "            'knowledge_sharing_score': np.random.beta(2, 2, self.n_farmers) * 100\n",
    "        }\n",
    "    \n",
    "    def generate_input_purchase_data(self):\n",
    "        \"\"\"Generate farm input purchase history\"\"\"\n",
    "        return {\n",
    "            'seed_investment_annual': np.random.lognormal(7, 0.6, self.n_farmers),\n",
    "            'fertilizer_usage_kg': np.random.gamma(2, 25, self.n_farmers),\n",
    "            'equipment_investment': np.random.lognormal(8, 1, self.n_farmers),\n",
    "            'input_timing_score': np.random.uniform(0.4, 0.95, self.n_farmers),\n",
    "            'quality_input_ratio': np.random.beta(3, 2, self.n_farmers),\n",
    "            'sustainable_practices_score': np.random.beta(2, 2, self.n_farmers) * 100\n",
    "        }\n",
    "    \n",
    "    def generate_target_variables(self, features_df):\n",
    "        \"\"\"Generate target variables based on features\"\"\"\n",
    "        # Climate-adjusted performance score\n",
    "        climate_impact = (\n",
    "            features_df['drought_risk_score'] * 0.3 + \n",
    "            features_df['flood_risk_score'] * 0.2 +\n",
    "            (100 - features_df['rainfall_forecast_mm']/10) * 0.2\n",
    "        ) / 100\n",
    "        \n",
    "        # Farmer performance (independent of climate)\n",
    "        farmer_performance = (\n",
    "            features_df['crop_health_score'] * 0.25 +\n",
    "            features_df['payment_consistency'] * 100 * 0.25 +\n",
    "            features_df['community_trust_score'] * 0.25 +\n",
    "            features_df['input_timing_score'] * 100 * 0.25\n",
    "        ) / 100\n",
    "        \n",
    "        # Credit score (0-850 scale)\n",
    "        base_score = 300 + (farmer_performance * 400)\n",
    "        climate_adjustment = np.clip(climate_impact * 150, -100, 50)\n",
    "        credit_score = np.clip(base_score - climate_adjustment, 300, 850)\n",
    "        \n",
    "        return {\n",
    "            'credit_score': credit_score,\n",
    "            'farmer_performance_score': farmer_performance * 100,\n",
    "            'climate_risk_score': climate_impact * 100,\n",
    "            'loan_default_probability': 1 / (1 + np.exp((credit_score - 500) / 100))\n",
    "        }\n",
    "    \n",
    "    def generate_complete_dataset(self):\n",
    "        \"\"\"Generate complete synthetic dataset\"\"\"\n",
    "        data = {}\n",
    "        \n",
    "        # Generate all feature categories\n",
    "        data.update(self.generate_satellite_data())\n",
    "        data.update(self.generate_climate_data())\n",
    "        data.update(self.generate_mpesa_data())\n",
    "        data.update(self.generate_community_data())\n",
    "        data.update(self.generate_input_purchase_data())\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Add farmer IDs and metadata\n",
    "        df['farmer_id'] = [f'KE_{i:06d}' for i in range(self.n_farmers)]\n",
    "        df['region'] = np.random.choice(['Central', 'Eastern', 'Western', 'Rift Valley'], self.n_farmers)\n",
    "        df['crop_type'] = np.random.choice(['Maize', 'Coffee', 'Tea', 'Beans', 'Sugarcane'], self.n_farmers)\n",
    "        \n",
    "        # Generate target variables\n",
    "        targets = self.generate_target_variables(df)\n",
    "        df.update(targets)\n",
    "        \n",
    "        return df\n",
    "\n",
    "# Generate synthetic dataset\n",
    "data_generator = ShambaScoreDataGenerator(n_farmers=2000)\n",
    "df = data_generator.generate_complete_dataset()\n",
    "\n",
    "print(f\"üìä Generated dataset with {len(df)} farmers\")\n",
    "print(f\"üìà Features: {len(df.columns)} columns\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Climate Risk Separation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class ClimateRiskSeparator:\n",
    "    \"\"\"Separate climate-related risks from farmer performance\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.climate_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        self.performance_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        \n",
    "    def fit(self, df):\n",
    "        # Climate-related features\n",
    "        climate_features = [\n",
    "            'rainfall_forecast_mm', 'temperature_avg_c', 'drought_risk_score',\n",
    "            'flood_risk_score', 'climate_variability_index', 'seasonal_pattern_match',\n",
    "            'soil_moisture_index'\n",
    "        ]\n",
    "        \n",
    "        # Farmer performance features\n",
    "        performance_features = [\n",
    "            'crop_health_score', 'payment_consistency', 'community_trust_score',\n",
    "            'input_timing_score', 'savings_rate', 'agricultural_payments_ratio',\n",
    "            'sustainable_practices_score', 'quality_input_ratio'\n",
    "        ]\n",
    "        \n",
    "        # Train climate risk model\n",
    "        X_climate = df[climate_features]\n",
    "        y_climate = df['climate_risk_score']\n",
    "        self.climate_model.fit(X_climate, y_climate)\n",
    "        \n",
    "        # Train farmer performance model\n",
    "        X_performance = df[performance_features]\n",
    "        y_performance = df['farmer_performance_score']\n",
    "        self.performance_model.fit(X_performance, y_performance)\n",
    "        \n",
    "        # Store feature names\n",
    "        self.climate_features = climate_features\n",
    "        self.performance_features = performance_features\n",
    "        \n",
    "        print(\"‚úÖ Climate Risk Separator trained successfully\")\n",
    "        \n",
    "    def predict_separated_scores(self, df):\n",
    "        \"\"\"Predict separated climate and performance scores\"\"\"\n",
    "        climate_risk = self.climate_model.predict(df[self.climate_features])\n",
    "        farmer_performance = self.performance_model.predict(df[self.performance_features])\n",
    "        \n",
    "        return climate_risk, farmer_performance\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"Get feature importance for transparency\"\"\"\n",
    "        climate_importance = dict(zip(\n",
    "            self.climate_features, \n",
    "            self.climate_model.feature_importances_\n",
    "        ))\n",
    "        \n",
    "        performance_importance = dict(zip(\n",
    "            self.performance_features,\n",
    "            self.performance_model.feature_importances_\n",
    "        ))\n",
    "        \n",
    "        return climate_importance, performance_importance\n",
    "\n",
    "# Train the separator\n",
    "separator = ClimateRiskSeparator()\n",
    "separator.fit(df)\n",
    "\n",
    "# Get feature importance\n",
    "climate_imp, performance_imp = separator.get_feature_importance()\n",
    "\n",
    "print(\"\\nüå°Ô∏è Top Climate Risk Factors:\")\n",
    "for feature, importance in sorted(climate_imp.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"  {feature}: {importance:.3f}\")\n",
    "\n",
    "print(\"\\nüë®‚Äçüåæ Top Performance Factors:\")\n",
    "for feature, importance in sorted(performance_imp.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(f\"  {feature}: {importance:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fair Credit Scoring Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class ShambaScoreModel:\n",
    "    \"\"\"Main Shamba Score credit scoring model\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = xgb.XGBRegressor(\n",
    "            n_estimators=200,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_names = None\n",
    "        \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"Prepare features for model training\"\"\"\n",
    "        # Select all relevant features except targets\n",
    "        exclude_cols = [\n",
    "            'farmer_id', 'credit_score', 'farmer_performance_score', \n",
    "            'climate_risk_score', 'loan_default_probability'\n",
    "        ]\n",
    "        \n",
    "        feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "        \n",
    "        # Handle categorical variables\n",
    "        df_processed = df.copy()\n",
    "        \n",
    "        # Encode categorical variables\n",
    "        le_region = LabelEncoder()\n",
    "        le_crop = LabelEncoder()\n",
    "        \n",
    "        df_processed['region_encoded'] = le_region.fit_transform(df_processed['region'])\n",
    "        df_processed['crop_type_encoded'] = le_crop.fit_transform(df_processed['crop_type'])\n",
    "        \n",
    "        # Remove original categorical columns\n",
    "        feature_cols = [col for col in feature_cols if col not in ['region', 'crop_type']]\n",
    "        feature_cols.extend(['region_encoded', 'crop_type_encoded'])\n",
    "        \n",
    "        return df_processed[feature_cols], feature_cols\n",
    "    \n",
    "    def fit(self, df):\n",
    "        \"\"\"Train the Shamba Score model\"\"\"\n",
    "        X, feature_names = self.prepare_features(df)\n",
    "        y = df['credit_score']\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        # Train model\n",
    "        self.model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        train_pred = self.model.predict(X_train_scaled)\n",
    "        test_pred = self.model.predict(X_test_scaled)\n",
    "        \n",
    "        train_r2 = r2_score(y_train, train_pred)\n",
    "        test_r2 = r2_score(y_test, test_pred)\n",
    "        \n",
    "        self.feature_names = feature_names\n",
    "        \n",
    "        print(f\"‚úÖ Shamba Score Model trained successfully\")\n",
    "        print(f\"üìä Training R¬≤: {train_r2:.3f}\")\n",
    "        print(f\"üìä Testing R¬≤: {test_r2:.3f}\")\n",
    "        \n",
    "        return X_test, y_test, test_pred\n",
    "    \n",
    "    def predict_score(self, farmer_data):\n",
    "        \"\"\"Predict credit score for a single farmer\"\"\"\n",
    "        X, _ = self.prepare_features(farmer_data)\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        score = self.model.predict(X_scaled)[0]\n",
    "        \n",
    "        return np.clip(score, 300, 850)\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"Get feature importance for model transparency\"\"\"\n",
    "        importance = dict(zip(self.feature_names, self.model.feature_importances_))\n",
    "        return sorted(importance.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Train the main model\n",
    "shamba_model = ShambaScoreModel()\n",
    "X_test, y_test, y_pred = shamba_model.fit(df)\n",
    "\n",
    "# Show top features\n",
    "print(\"\\nüéØ Top 10 Most Important Features:\")\n",
    "for i, (feature, importance) in enumerate(shamba_model.get_feature_importance()[:10]):\n",
    "    print(f\"  {i+1}. {feature}: {importance:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fairness & Bias Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class FairnessAnalyzer:\n",
    "    \"\"\"Analyze model fairness across different groups\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def analyze_regional_fairness(self, df, predictions):\n",
    "        \"\"\"Analyze fairness across regions\"\"\"\n",
    "        df_analysis = df.copy()\n",
    "        df_analysis['predicted_score'] = predictions\n",
    "        \n",
    "        regional_stats = df_analysis.groupby('region').agg({\n",
    "            'predicted_score': ['mean', 'std', 'count'],\n",
    "            'climate_risk_score': 'mean',\n",
    "            'farmer_performance_score': 'mean'\n",
    "        }).round(2)\n",
    "        \n",
    "        print(\"üåç Regional Fairness Analysis:\")\n",
    "        print(regional_stats)\n",
    "        \n",
    "        return regional_stats\n",
    "    \n",
    "    def analyze_crop_fairness(self, df, predictions):\n",
    "        \"\"\"Analyze fairness across crop types\"\"\"\n",
    "        df_analysis = df.copy()\n",
    "        df_analysis['predicted_score'] = predictions\n",
    "        \n",
    "        crop_stats = df_analysis.groupby('crop_type').agg({\n",
    "            'predicted_score': ['mean', 'std', 'count'],\n",
    "            'climate_risk_score': 'mean',\n",
    "            'farmer_performance_score': 'mean'\n",
    "        }).round(2)\n",
    "        \n",
    "        print(\"\\nüåæ Crop Type Fairness Analysis:\")\n",
    "        print(crop_stats)\n",
    "        \n",
    "        return crop_stats\n",
    "    \n",
    "    def detect_bias(self, df, predictions, threshold=0.1):\n",
    "        \"\"\"Detect potential bias in predictions\"\"\"\n",
    "        df_analysis = df.copy()\n",
    "        df_analysis['predicted_score'] = predictions\n",
    "        \n",
    "        # Check for correlation between protected attributes and residuals\n",
    "        df_analysis['residual'] = df_analysis['credit_score'] - df_analysis['predicted_score']\n",
    "        \n",
    "        bias_metrics = {}\n",
    "        \n",
    "        # Regional bias\n",
    "        regional_residuals = df_analysis.groupby('region')['residual'].mean()\n",
    "        bias_metrics['regional_bias'] = regional_residuals.std()\n",
    "        \n",
    "        # Crop type bias\n",
    "        crop_residuals = df_analysis.groupby('crop_type')['residual'].mean()\n",
    "        bias_metrics['crop_bias'] = crop_residuals.std()\n",
    "        \n",
    "        print(\"\\n‚öñÔ∏è Bias Detection Results:\")\n",
    "        for metric, value in bias_metrics.items():\n",
    "            status = \"‚úÖ Low\" if value < threshold else \"‚ö†Ô∏è High\"\n",
    "            print(f\"  {metric}: {value:.3f} ({status})\")\n",
    "        \n",
    "        return bias_metrics\n",
    "\n",
    "# Analyze fairness\n",
    "fairness_analyzer = FairnessAnalyzer()\n",
    "regional_fairness = fairness_analyzer.analyze_regional_fairness(df.iloc[len(X_test):], y_pred)\n",
    "crop_fairness = fairness_analyzer.analyze_crop_fairness(df.iloc[len(X_test):], y_pred)\n",
    "bias_metrics = fairness_analyzer.detect_bias(df.iloc[len(X_test):], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explainable AI & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class ShambaScoreExplainer:\n",
    "    \"\"\"Provide explanations and recommendations for credit scores\"\"\"\n",
    "    \n",
    "    def __init__(self, model, separator):\n",
    "        self.model = model\n",
    "        self.separator = separator\n",
    "        \n",
    "    def explain_score(self, farmer_data):\n",
    "        \"\"\"Provide detailed explanation of credit score\"\"\"\n",
    "        # Get predictions\n",
    "        credit_score = self.model.predict_score(farmer_data)\n",
    "        climate_risk, farmer_performance = self.separator.predict_separated_scores(farmer_data)\n",
    "        \n",
    "        # Get feature contributions\n",
    "        feature_importance = dict(self.model.get_feature_importance())\n",
    "        \n",
    "        explanation = {\n",
    "            'credit_score': round(credit_score, 0),\n",
    "            'score_category': self._categorize_score(credit_score),\n",
    "            'climate_risk': round(climate_risk[0], 1),\n",
    "            'farmer_performance': round(farmer_performance[0], 1),\n",
    "            'key_strengths': self._identify_strengths(farmer_data, feature_importance),\n",
    "            'improvement_areas': self._identify_weaknesses(farmer_data, feature_importance),\n",
    "            'climate_factors': self._explain_climate_impact(farmer_data)\n",
    "        }\n",
    "        \n",
    "        return explanation\n",
    "    \n",
    "    def _categorize_score(self, score):\n",
    "        \"\"\"Categorize credit score\"\"\"\n",
    "        if score >= 750:\n",
    "            return \"Excellent (750-850)\"\n",
    "        elif score >= 650:\n",
    "            return \"Good (650-749)\"\n",
    "        elif score >= 550:\n",
    "            return \"Fair (550-649)\"\n",
    "        else:\n",
    "            return \"Poor (300-549)\"\n",
    "    \n",
    "    def _identify_strengths(self, farmer_data, importance):\n",
    "        \"\"\"Identify farmer's key strengths\"\"\"\n",
    "        strengths = []\n",
    "        \n",
    "        if farmer_data['community_trust_score'].iloc[0] > 80:\n",
    "            strengths.append(\"Strong community reputation\")\n",
    "        if farmer_data['payment_consistency'].iloc[0] > 0.9:\n",
    "            strengths.append(\"Excellent payment history\")\n",
    "        if farmer_data['crop_health_score'].iloc[0] > 80:\n",
    "            strengths.append(\"High crop health indicators\")\n",
    "        if farmer_data['sustainable_practices_score'].iloc[0] > 75:\n",
    "            strengths.append(\"Good sustainable farming practices\")\n",
    "            \n",
    "        return strengths[:3]  # Top 3 strengths\n",
    "    \n",
    "    def _identify_weaknesses(self, farmer_data, importance):\n",
    "        \"\"\"Identify areas for improvement\"\"\"\n",
    "        improvements = []\n",
    "        \n",
    "        if farmer_data['savings_rate'].iloc[0] < 0.2:\n",
    "            improvements.append(\"Increase savings rate\")\n",
    "        if farmer_data['input_timing_score'].iloc[0] < 0.7:\n",
    "            improvements.append(\"Improve input timing\")\n",
    "        if farmer_data['equipment_investment'].iloc[0] < 10000:\n",
    "            improvements.append(\"Consider equipment upgrades\")\n",
    "        if farmer_data['fertilizer_usage_kg'].iloc[0] < 30:\n",
    "            improvements.append(\"Optimize fertilizer usage\")\n",
    "            \n",
    "        return improvements[:3]  # Top 3 improvements\n",
    "    \n",
    "    def _explain_climate_impact(self, farmer_data):\n",
    "        \"\"\"Explain climate-related factors\"\"\"\n",
    "        climate_factors = []\n",
    "        \n",
    "        drought_risk = farmer_data['drought_risk_score'].iloc[0]\n",
    "        flood_risk = farmer_data['flood_risk_score'].iloc[0]\n",
    "        \n",
    "        if drought_risk > 60:\n",
    "            climate_factors.append(f\"High drought risk ({drought_risk:.0f}%)\")\n",
    "        if flood_risk > 40:\n",
    "            climate_factors.append(f\"Elevated flood risk ({flood_risk:.0f}%)\")\n",
    "        if farmer_data['climate_variability_index'].iloc[0] > 0.6:\n",
    "            climate_factors.append(\"High climate variability in region\")\n",
    "            \n",
    "        return climate_factors\n",
    "    \n",
    "    def generate_recommendations(self, farmer_data, explanation):\n",
    "        \"\"\"Generate personalized recommendations\"\"\"\n",
    "        recommendations = {\n",
    "            'immediate_actions': [],\n",
    "            'medium_term_goals': [],\n",
    "            'climate_adaptation': [],\n",
    "            'financial_products': []\n",
    "        }\n",
    "        \n",
    "        score = explanation['credit_score']\n",
    "        \n",
    "        # Immediate actions\n",
    "        if farmer_data['savings_rate'].iloc[0] < 0.3:\n",
    "            recommendations['immediate_actions'].append(\n",
    "                \"Set up automatic savings of 10% of monthly income\"\n",
    "            )\n",
    "        \n",
    "        if farmer_data['cooperative_participation'].iloc[0] == 0:\n",
    "            recommendations['immediate_actions'].append(\n",
    "                \"Join local farmer cooperative for better market access\"\n",
    "            )\n",
    "        \n",
    "        # Medium-term goals\n",
    "        if farmer_data['sustainable_practices_score'].iloc[0] < 70:\n",
    "            recommendations['medium_term_goals'].append(\n",
    "                \"Adopt climate-smart agriculture practices\"\n",
    "            )\n",
    "        \n",
    "        # Climate adaptation\n",
    "        if explanation['climate_risk'] > 60:\n",
    "            recommendations['climate_adaptation'].append(\n",
    "                \"Consider drought-resistant crop varieties\"\n",
    "            )\n",
    "            recommendations['climate_adaptation'].append(\n",
    "                \"Invest in water conservation systems\"\n",
    "            )\n",
    "        \n",
    "        # Financial products\n",
    "        if score >= 650:\n",
    "            recommendations['financial_products'].append(\n",
    "                \"Eligible for premium agricultural loans (5-7% interest)\"\n",
    "            )\n",
    "        elif score >= 550:\n",
    "            recommendations['financial_products'].append(\n",
    "                \"Eligible for standard agricultural loans (8-12% interest)\"\n",
    "            )\n",
    "        else:\n",
    "            recommendations['financial_products'].append(\n",
    "                \"Focus on building credit history with micro-loans\"\n",
    "            )\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# Create explainer\n",
    "explainer = ShambaScoreExplainer(shamba_model, separator)\n",
    "\n",
    "# Example explanation for a single farmer\n",
    "sample_farmer = df.iloc[[0]]\n",
    "explanation = explainer.explain_score(sample_farmer)\n",
    "recommendations = explainer.generate_recommendations(sample_farmer, explanation)\n",
    "\n",
    "print(\"üéØ Sample Farmer Credit Score Explanation:\")\n",
    "print(f\"Credit Score: {explanation['credit_score']} ({explanation['score_category']})\")\n",
    "print(f\"Climate Risk: {explanation['climate_risk']}%\")\n",
    "print(f\"Farmer Performance: {explanation['farmer_performance']}%\")\n",
    "\n",
    "print(\"\\nüí™ Key Strengths:\")\n",
    "for strength in explanation['key_strengths']:\n",
    "    print(f\"  ‚Ä¢ {strength}\")\n",
    "\n",
    "print(\"\\nüìà Improvement Areas:\")\n",
    "for improvement in explanation['improvement_areas']:\n",
    "    print(f\"  ‚Ä¢ {improvement}\")\n",
    "\n",
    "print(\"\\nüå°Ô∏è Climate Factors:\")\n",
    "for factor in explanation['climate_factors']:\n",
    "    print(f\"  ‚Ä¢ {factor}\")\n",
    "\n",
    "print(\"\\nüí° Recommendations:\")\n",
    "for category, items in recommendations.items():\n",
    "    if items:\n",
    "        print(f\"  {category.replace('_', ' ').title()}:\")\n",
    "        for item in items:\n",
    "            print(f\"    - {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Validation & Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model performance visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# 1. Actual vs Predicted scores\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.plot([300, 850], [300, 850], 'r--', lw=2)\n",
    "plt.xlabel('Actual Credit Score')\n",
    "plt.ylabel('Predicted Credit Score')\n",
    "plt.title('Actual vs Predicted Scores')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Residuals plot\n",
    "plt.subplot(2, 3, 2)\n",
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_pred, residuals, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Credit Score')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals Plot')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Feature importance\n",
    "plt.subplot(2, 3, 3)\n",
    "top_features = shamba_model.get_feature_importance()[:10]\n",
    "features, importances = zip(*top_features)\n",
    "plt.barh(range(len(features)), importances)\n",
    "plt.yticks(range(len(features)), [f.replace('_', ' ').title() for f in features])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 10 Feature Importance')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Score distribution\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.hist(df['credit_score'], bins=30, alpha=0.7, label='Actual', density=True)\n",
    "plt.hist(y_pred, bins=30, alpha=0.7, label='Predicted', density=True)\n",
    "plt.xlabel('Credit Score')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Score Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Climate vs Performance separation\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.scatter(df['climate_risk_score'], df['farmer_performance_score'], \n",
    "           c=df['credit_score'], cmap='viridis', alpha=0.6)\n",
    "plt.colorbar(label='Credit Score')\n",
    "plt.xlabel('Climate Risk Score')\n",
    "plt.ylabel('Farmer Performance Score')\n",
    "plt.title('Climate Risk vs Performance')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Regional score distribution\n",
    "plt.subplot(2, 3, 6)\n",
    "df.boxplot(column='credit_score', by='region', ax=plt.gca())\n",
    "plt.title('Credit Score by Region')\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"\\nüìä Model Performance Metrics:\")\n",
    "print(f\"R¬≤ Score: {r2_score(y_test, y_pred):.3f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.2f}\")\n",
    "print(f\"Mean Absolute Error: {np.mean(np.abs(y_test - y_pred)):.2f}\")\n",
    "\n",
    "# Score distribution by category\n",
    "score_categories = pd.cut(y_pred, bins=[300, 550, 650, 750, 850], \n",
    "                         labels=['Poor', 'Fair', 'Good', 'Excellent'])\n",
    "print(\"\\nüéØ Predicted Score Distribution:\")\n",
    "print(score_categories.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. API Integration Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import joblib\n",
    "import json\n",
    "\n",
    "class ShambaScoreAPI:\n",
    "    \"\"\"API wrapper for Shamba Score model\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.separator = None\n",
    "        self.explainer = None\n",
    "        \n",
    "    def load_models(self, model_path='../models/'):\n",
    "        \"\"\"Load trained models\"\"\"\n",
    "        try:\n",
    "            self.model = joblib.load(f'{model_path}shamba_score_model.pkl')\n",
    "            self.separator = joblib.load(f'{model_path}climate_separator.pkl')\n",
    "            self.explainer = ShambaScoreExplainer(self.model, self.separator)\n",
    "            print(\"‚úÖ Models loaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading models: {e}\")\n",
    "    \n",
    "    def save_models(self, model_path='../models/'):\n",
    "        \"\"\"Save trained models\"\"\"\n",
    "        try:\n",
    "            joblib.dump(shamba_model, f'{model_path}shamba_score_model.pkl')\n",
    "            joblib.dump(separator, f'{model_path}climate_separator.pkl')\n",
    "            print(\"‚úÖ Models saved successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving models: {e}\")\n",
    "    \n",
    "    def score_farmer(self, farmer_data_json):\n",
    "        \"\"\"Score a farmer from JSON input\"\"\"\n",
    "        try:\n",
    "            # Parse input data\n",
    "            farmer_data = json.loads(farmer_data_json) if isinstance(farmer_data_json, str) else farmer_data_json\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            df_farmer = pd.DataFrame([farmer_data])\n",
    "            \n",
    "            # Get explanation and recommendations\n",
    "            explanation = self.explainer.explain_score(df_farmer)\n",
    "            recommendations = self.explainer.generate_recommendations(df_farmer, explanation)\n",
    "            \n",
    "            # Combine results\n",
    "            result = {\n",
    "                'farmer_id': farmer_data.get('farmer_id', 'unknown'),\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'credit_score': explanation['credit_score'],\n",
    "                'score_category': explanation['score_category'],\n",
    "                'climate_risk_score': explanation['climate_risk'],\n",
    "                'farmer_performance_score': explanation['farmer_performance'],\n",
    "                'key_strengths': explanation['key_strengths'],\n",
    "                'improvement_areas': explanation['improvement_areas'],\n",
    "                'climate_factors': explanation['climate_factors'],\n",
    "                'recommendations': recommendations,\n",
    "                'model_version': '1.0',\n",
    "                'confidence_score': min(95, max(60, 100 - abs(explanation['climate_risk'] - 50)))\n",
    "            }\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'error': str(e),\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "    \n",
    "    def batch_score(self, farmers_data):\n",
    "        \"\"\"Score multiple farmers\"\"\"\n",
    "        results = []\n",
    "        for farmer_data in farmers_data:\n",
    "            result = self.score_farmer(farmer_data)\n",
    "            results.append(result)\n",
    "        return results\n",
    "\n",
    "# Initialize API\n",
    "api = ShambaScoreAPI()\n",
    "api.model = shamba_model\n",
    "api.separator = separator\n",
    "api.explainer = explainer\n",
    "\n",
    "# Save models for production use\n",
    "api.save_models()\n",
    "\n",
    "# Test API with sample data\n",
    "sample_farmer_json = {\n",
    "    'farmer_id': 'KE_000001',\n",
    "    'ndvi_current': 0.75,\n",
    "    'crop_health_score': 85,\n",
    "    'monthly_income_avg': 25000,\n",
    "    'payment_consistency': 0.95,\n",
    "    'community_trust_score': 88,\n",
    "    'drought_risk_score': 35,\n",
    "    'flood_risk_score': 20,\n",
    "    'savings_rate': 0.15,\n",
    "    'region': 'Central',\n",
    "    'crop_type': 'Maize'\n",
    "}\n",
    "\n",
    "# Add missing required fields with defaults\n",
    "required_fields = {\n",
    "    'ndvi_historical_avg': 0.65,\n",
    "    'field_size_hectares': 2.5,\n",
    "    'vegetation_consistency': 0.8,\n",
    "    'soil_moisture_index': 0.6,\n",
    "    'rainfall_forecast_mm': 120,\n",
    "    'temperature_avg_c': 24,\n",
    "    'climate_variability_index': 0.4,\n",
    "    'seasonal_pattern_match': 0.85,\n",
    "    'transaction_frequency': 30,\n",
    "    'agricultural_payments_ratio': 0.6,\n",
    "    'seasonal_income_stability': 0.7,\n",
    "    'cooperative_participation': 1,\n",
    "    'peer_recommendations': 4,\n",
    "    'local_leadership_role': 0,\n",
    "    'dispute_history': 0,\n",
    "    'knowledge_sharing_score': 75,\n",
    "    'seed_investment_annual': 8000,\n",
    "    'fertilizer_usage_kg': 45,\n",
    "    'equipment_investment': 15000,\n",
    "    'input_timing_score': 0.85,\n",
    "    'quality_input_ratio': 0.8,\n",
    "    'sustainable_practices_score': 70\n",
    "}\n",
    "\n",
    "sample_farmer_json.update(required_fields)\n",
    "\n",
    "# Test API\n",
    "api_result = api.score_farmer(sample_farmer_json)\n",
    "\n",
    "print(\"\\nüöÄ API Test Result:\")\n",
    "print(json.dumps(api_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary & Next Steps\n",
    "\n",
    "### ‚úÖ What We've Built:\n",
    "1. **Climate-Adaptive Credit Scoring**: Separates climate risks from farmer performance\n",
    "2. **Multi-Source Data Integration**: Satellite imagery, climate data, M-Pesa, community scores\n",
    "3. **Fairness Analysis**: Ensures equitable scoring across regions and crop types\n",
    "4. **Explainable AI**: Transparent explanations and personalized recommendations\n",
    "5. **Production-Ready API**: Easy integration with frontend applications\n",
    "\n",
    "### üéØ Key Features:\n",
    "- **Fair Scoring**: Accounts for climate factors beyond farmer control\n",
    "- **Transparent**: Clear explanations for every score\n",
    "- **Actionable**: Specific recommendations for improvement\n",
    "- **Scalable**: Handles batch processing for multiple farmers\n",
    "- **Robust**: Comprehensive validation and bias detection\n",
    "\n",
    "### üöÄ Next Steps for Production:\n",
    "1. **Real Data Integration**: Connect to actual satellite APIs, weather services\n",
    "2. **Model Retraining**: Implement continuous learning pipeline\n",
    "3. **A/B Testing**: Validate model performance in real-world scenarios\n",
    "4. **Regulatory Compliance**: Ensure adherence to financial regulations\n",
    "5. **Monitoring**: Set up model drift detection and performance monitoring"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}